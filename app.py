#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
from pathlib import Path
import pandas as pd
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import create_agent
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import uuid

SUGGESTION_HEADER = "ä½ è¿˜å¯ä»¥ç»§ç»­æ¢ç´¢ ğŸ‘‡"


def suggestion_block():
    return (
        f"\n\n{SUGGESTION_HEADER}\n\n"
        "ğŸ” 1. åŠŸèƒ½ä¸ç–¾ç—…ï¼ˆOpenTargetsï¼‰\n"
        "ğŸ§¬ 2. è°ƒæ§ç½‘ç»œï¼ˆTRRUSTï¼‰\n"
        "ğŸ§  3. è™šæ‹Ÿæ‰°åŠ¨è§£æï¼ˆBrainBeaconï¼‰\n"
        "ğŸ›¤ï¸ 4. ä¿¡å·é€šè·¯ï¼ˆReactomeï¼‰\n"
        "ğŸ“š 5. æœ€æ–°æ–‡çŒ®ï¼ˆPubMed/semanticï¼‰\n\n"
        "è¾“å…¥ 1â€“5 å³å¯ç»§ç»­ã€‚"
    )


def append_suggestions(text: str) -> str:
    """Ensure suggestion block appears at most once."""
    text = text or ""
    if SUGGESTION_HEADER in text:
        return text
    return text + suggestion_block()


BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
GENE_PATTERN = re.compile(r"\b[A-Za-z0-9]{2,10}\b")


def load_default_ko_gene() -> str | None:
    """Load KO top1 gene as default fallback."""
    csv_path = DATA_DIR / "gene_scores.csv"
    try:
        df = pd.read_csv(csv_path)
        top_gene = df.sort_values("score_sum", ascending=False).iloc[0]["genes"]
        return str(top_gene).upper()
    except Exception:
        return None


DEFAULT_KO_GENE = load_default_ko_gene()


def set_last_gene(session: dict, gene: str) -> None:
    if not gene:
        return
    session["last_gene"] = gene.upper()


def resolve_gene(session: dict) -> tuple[str | None, bool]:
    """Return active gene for session, optionally falling back to KO top1."""
    gene = session.get("last_gene")
    used_default = False
    if not gene and DEFAULT_KO_GENE:
        gene = DEFAULT_KO_GENE
        session["last_gene"] = gene
        used_default = True
    return gene, used_default


def gene_notice(gene: str, used_default: bool, context: str = "") -> str:
    if not used_default or not gene:
        return ""
    suffix = context if context else ""
    return (
        f"æœªæ£€æµ‹åˆ°æ‚¨è¾“å…¥æ–°çš„åŸºå› ï¼Œæœ¬æ¬¡é»˜è®¤ä½¿ç”¨ BrainBeacon KO Top1 åŸºå›  **{gene}**"
        f"{suffix}ã€‚\n\n"
    )


def extract_genes(text: str) -> list[str]:
    """Extract likely gene symbols from free text."""
    if not text:
        return []
    candidates = GENE_PATTERN.findall(text)
    genes = []
    for token in candidates:
        if any(ch.isdigit() for ch in token) or token.isupper():
            genes.append(token.upper())
    return genes

# === è‡ªå®šä¹‰å·¥å…· ===
from tools.csv_analyzer import analyze_csv
from tools.tf_coregulation_tool import check_tf_coregulation
from tools.opentargets_tool import opentargets_query
from tools.brainbeacon_ko_tool import brainbeacon_ko_summary
from tools.memory_setup import setup_memory
from tools.literature_search import search_papers
from tools.reactome_tool import query_pathways

# =============================
# åˆå§‹åŒ– Flask åº”ç”¨
# =============================
app = Flask(__name__)
CORS(app)

# =============================
# ç¯å¢ƒå˜é‡
# =============================
load_dotenv()
api_key = os.getenv("DS_API_KEY") or os.getenv("OPENAI_API_KEY")
base_url = "https://api.deepseek.com/v1" if os.getenv("DS_API_KEY") else None

# =============================
# åˆå§‹åŒ– LLM æ¨¡å‹
# =============================
llm = ChatOpenAI(
    model="deepseek-chat",
    temperature=0,
    openai_api_key=api_key,
    openai_api_base=base_url,
)

# =============================
# å¼ºåŒ–ç‰ˆ system_prompt
# =============================
system_prompt = SystemMessage(
    content=(
        "ä½ æ˜¯ä¸€åç§‘ç ”æ™ºèƒ½åŠ©ç†ï¼Œèƒ½å¤Ÿä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š\n"
        "- analyze_csvï¼šåˆ†æç”¨æˆ·æŒ‡å®šçš„ CSV æ–‡ä»¶ï¼›\n"
        "- brainbeacon_ko_summaryï¼šåˆ†æ BrainBeacon æ•²é™¤/è¿‡è¡¨è¾¾ï¼ˆKO/OEï¼‰å®éªŒï¼Œ"
        "è‡ªåŠ¨è¯»å– data/gene_scores.csvï¼›\n"
        "- check_tf_coregulationï¼šæŸ¥è¯¢ TRRUST è½¬å½•å› å­è°ƒæ§å…³ç³»ï¼›\n"
        "- query_opentargetsï¼šæŸ¥è¯¢åŸºå› åŠŸèƒ½ä¸ç–¾ç—…å…³è”ã€‚\n\n"

        "==============================\n"
        "ã€å¿…é¡»éµå®ˆçš„æ ¸å¿ƒè§„åˆ™ã€‘\n"
        "==============================\n"
        "â‘  å½“ç”¨æˆ·æåˆ°ä»¥ä¸‹å…³é”®è¯æ—¶ï¼Œä½ å¿…é¡»è‡ªåŠ¨è°ƒç”¨ brainbeacon_ko_summaryï¼š\n"
        "   â€œBrainBeacon æ•²é™¤â€ã€ â€œKO å“ªäº› gene æœ€å¼ºâ€ã€ â€œKO åæœ€æ˜¾è‘—å˜åŒ–â€ã€\n"
        "   â€œæ•²é™¤å®éªŒç»“æœâ€ã€ â€œOE å®éªŒâ€ã€ â€œè™šæ‹Ÿæ‰°åŠ¨ç»“æœâ€ã€\n"
        "   â€œå“ªäº›åŸºå› æœ€æ˜¾è‘—/æœ€å¼º/å½±å“æœ€å¤§â€ã€‚\n"
        "   - ä¸è¦è¦æ±‚ç”¨æˆ·æä¾› CSV è·¯å¾„ï¼›\n"
        "   - ä¸è¦åé—®ï¼›\n"
        "   - è‡ªåŠ¨è°ƒç”¨ brainbeacon_ko_summaryã€‚\n\n"

        "â‘¡ å¯¹äº TRRUSTï¼ˆcheck_tf_coregulationï¼‰ï¼š\n"
        "   - è‹¥ç”¨æˆ·æœªæŒ‡å®šç‰©ç§ï¼Œå…ˆä»¥ species='auto' è°ƒç”¨ï¼›\n"
        "   - å¦‚æœ human ä¸ mouse éƒ½å­˜åœ¨ç»“æœï¼Œä½ éœ€è¦æç¤ºç”¨æˆ·é€‰æ‹©ç‰©ç§ï¼›\n"
        "   - ç”¨æˆ·æ˜ç¡® species åï¼Œå†æ¬¡è°ƒç”¨å¹¶ç»™å‡ºç²¾ç¡®å›ç­”ã€‚\n\n"

        "â‘¢ å¯¹äº OpenTargetsï¼ˆquery_opentargetsï¼‰ï¼š\n"
        "   - è¾“å…¥åŸºå› åç§°å³å¯è·å–åŠŸèƒ½ã€ç–¾ç—…å…³è”å’Œ gene typeã€‚\n\n"

        "â‘£ æ‰€æœ‰å›ç­”å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼Œå¹¶ä¿æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ä¸€è‡´ã€‚\n"
        "   å›ç­”éœ€å­¦æœ¯ã€å‡†ç¡®ã€é€»è¾‘æ¸…æ™°ã€‚\n"
    )
)

# =============================
# å·¥å…·æ³¨å†Œä¸è®°å¿†è®¾ç½®
# =============================
tools = [
    analyze_csv,
    check_tf_coregulation,
    opentargets_query,
    brainbeacon_ko_summary,
    search_papers,
    query_pathways
]

checkpointer, store = setup_memory()

# =============================
# æ„å»º Agentï¼ˆå«çŸ­æœŸè®°å¿†ï¼‰
# =============================
agent = create_agent(
    model=llm,
    tools=tools,
    checkpointer=checkpointer,
    store=store,
)

# å­˜å‚¨æ¯ä¸ªä¼šè¯çš„æ¶ˆæ¯å†å²
sessions = {}

IDENTITY_RESPONSE = (
    "æˆ‘æ˜¯å¤§è„‘å¯æ™ºï¼ˆBrainBeaconï¼‰çš„æ™ºèƒ½åŠ©ç†ï¼Œä¸“ä¸ºå¤šæ¨¡æ€ä¸è·¨ç‰©ç§ç©ºé—´è½¬å½•ç»„ç ”ç©¶è®¾è®¡ã€‚\n\n"
    "ä½œä¸ºæ‚¨çš„ç ”ç©¶ä¼™ä¼´ï¼Œæˆ‘å¯ä»¥å¸®åŠ©æ‚¨å¤„ç†å¤šä¸ªå±‚é¢çš„ç”Ÿç‰©ä¿¡æ¯å­¦ä»»åŠ¡ï¼š\n\n"
    "â¸»\n\n"
    "ğŸ§  âœ¨ **æ ¸å¿ƒèƒ½åŠ›ï¼šBrainBeacon è™šæ‹Ÿç©ºé—´æ‰°åŠ¨åˆ†æ**\n"
    "æˆ‘ä¸ BrainBeaconï¼ˆå¤§è„‘å¯æ™ºï¼‰æ¨¡å‹æ·±åº¦é›†æˆï¼Œèƒ½å¤Ÿï¼š\n"
    "- è‡ªåŠ¨åˆ†æåŸºå› æ•²é™¤ï¼ˆKOï¼‰ä¸è¿‡è¡¨è¾¾ï¼ˆOEï¼‰çš„ç©ºé—´æ‰°åŠ¨ç»“æœ\n"
    "- æå–æœ€æ˜¾è‘—å˜åŒ–åŸºå› ä¸å¾®ç¯å¢ƒå˜åŒ–\n"
    "- è§£è¯»ç›®æ ‡åŸºå› å¯¹é‚»åŸŸç»†èƒçš„å½±å“\n\n"
    "è¿™æ˜¯æˆ‘çš„æ ¸å¿ƒä¸“é•¿ â€”â€” æ™ºèƒ½è§£è¯» BrainBeacon äº§ç”Ÿçš„è™šæ‹Ÿæ‰°åŠ¨æ•°æ®ã€‚\n\n"
    "â¸»\n\n"
    "ğŸ”¬ **æ•°æ®åˆ†æèƒ½åŠ›**\n"
    "- è‡ªåŠ¨æå–æœ€æ˜¾è‘—å˜åŒ–çš„åŸºå› \n"
    "- æ¯”è¾ƒæ‰°åŠ¨å‰åç»†èƒ embedding çš„å˜åŒ–\n"
    "- æ±‡æ€» KO/OE ç»“æœï¼Œç”Ÿæˆæ¸…æ™°ã€ç”Ÿç‰©å­¦å¯¼å‘çš„è§£é‡Š\n\n"
    "â¸»\n\n"
    "ğŸ§¬ **åŸºå› è°ƒæ§ç½‘ç»œæŸ¥è¯¢**\n"
    "- åŸºäº TRRUST æŸ¥è¯¢è½¬å½•å› å­è°ƒæ§å…³ç³»\n"
    "- è¿›è¡Œå…±è°ƒæ§åˆ†æï¼ˆè‡ªåŠ¨è¯†åˆ« human/mouseï¼Œç‰©ç§ä¸æ˜ç¡®æ—¶ä¼šè¯¢é—®æ‚¨ï¼‰\n"
    "- æä¾›è½¬å½•å› å­ â†’ é¶åŸºå› çš„è°ƒæ§æ–¹å¼ï¼ˆæ¿€æ´»/æŠ‘åˆ¶ï¼‰\n\n"
    "â¸»\n\n"
    "ğŸ¯ **åŸºå› åŠŸèƒ½ä¸ç–¾ç—…å…³è”æŸ¥è¯¢**\n"
    "- æ¥å…¥ OpenTargets API è·å–åŸºå› åŠŸèƒ½\n"
    "- æä¾›ç›¸å…³ç–¾ç—…ä¸å…³è”è¯„åˆ†\n"
    "- æ±‡æ€»å…³é”®é€šè·¯æˆ–ç”Ÿç‰©å­¦è¿‡ç¨‹\n\n"
    "â¸»\n\n"
    "ğŸ’¡ **æˆ‘çš„ç‰¹ç‚¹**\n"
    "- ç†è§£ä¸Šä¸‹æ–‡å¹¶ä¿æŒå¤šè½®å¯¹è¯ä¸€è‡´\n"
    "- è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·è¿›è¡Œåˆ†æ\n"
    "- æ”¯æŒè·¨ç‰©ç§ã€è·¨å¹³å°çš„ç©ºé—´è½¬å½•ç»„ä»»åŠ¡\n\n"
    "â¸»\n\n"
    "ğŸ—£ï¸ æ‚¨ç°åœ¨æƒ³æŸ¥è¯¢åŸºå› åŠŸèƒ½ã€è°ƒæ§ç½‘ç»œï¼Œè¿˜æ˜¯è®©å¤§è„‘å¯æ™ºå¸®æ‚¨åˆ†æä¸€æ¬¡è™šæ‹Ÿæ‰°åŠ¨ï¼Ÿ"
)


# =============================
# è·¯ç”±
# =============================
@app.route('/')
def index():
    return render_template('index.html')


@app.route('/api/chat', methods=['POST'])
def chat():
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    try:
        data = request.json
        user_message = data.get('message', '')
        session_id = data.get('session_id', 'default')

        if not user_message:
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400

        # åˆå§‹åŒ–ä¼šè¯
        if session_id not in sessions:
            sessions[session_id] = {
                'messages': [system_prompt],
                'thread_id': f"thread_{session_id}",
                'last_gene': None
            }

        session = sessions[session_id]

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        session['messages'].append(HumanMessage(content=user_message))

        normalized = user_message.strip().lower()
        identity_keywords = [
            "ä½ æ˜¯è°", "ä½ æ˜¯èª°", "who are you", "ä½ å«ä»€ä¹ˆ", "ä½ å«ä»€éº¼",
            "ä½ æ˜¯å¹²ä»€ä¹ˆçš„", "ä½ æ˜¯å¹²ç”šéº¼çš„", "ä½ å¯ä»¥åšä»€ä¹ˆ", "ä½ èƒ½åšä»€ä¹ˆ",
            "who r u", "what can you do"
        ]

        if any(keyword in user_message or keyword in normalized for keyword in identity_keywords):
            reply_content = IDENTITY_RESPONSE
            session['messages'].append(AIMessage(content=reply_content))
            return jsonify({
                "response": reply_content,
                "session_id": session_id
            })

        # =============================
        # èœå•æ•°å­—è¯†åˆ«ï¼ˆ1â€“5 è‡ªåŠ¨æ˜ å°„å·¥å…·ï¼‰
        # =============================
        if normalized in ["1", "2", "3", "4", "5"]:
            if normalized == "1":
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "æš‚æœªæ£€æµ‹åˆ°å¯ç”¨çš„åŸºå› ï¼Œè¯·å…ˆè¾“å…¥åŸºå› åç§°ã€‚"
                else:
                    result = opentargets_query.run({"gene_symbol": gene})
                    reply = gene_notice(gene, used_default, " è¿›è¡Œ OpenTargets æŸ¥è¯¢") + result
            elif normalized == "2":
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "è¯·å‘Šè¯‰æˆ‘è¦æŸ¥è¯¢çš„è½¬å½•å› å­æˆ–åŸºå› åç§°ã€‚"
                else:
                    result = check_tf_coregulation.run({
                        "tf_list_str": "",
                        "target_gene": gene,
                        "species": "auto"
                    })
                    reply = gene_notice(gene, used_default, " æŸ¥è¯¢ TRRUST è°ƒæ§ç½‘ç»œ") + result
            elif normalized == "3":
                reply = brainbeacon_ko_summary.run({})
            elif normalized == "4":
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "è¯·æä¾›è¦æŸ¥è¯¢çš„åŸºå› åç§°ï¼Œæˆ‘æ‰èƒ½æ£€ç´¢ Reactome é€šè·¯ã€‚"
                else:
                    result = query_pathways.run({
                        "input_data": {
                            "query_gene": gene,
                            "limit": 10
                        }
                    })
                    reply = gene_notice(gene, used_default, " æŸ¥è¯¢ Reactome é€šè·¯") + result
            elif normalized == "5":
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "è¯·å‘Šè¯‰æˆ‘éœ€è¦æ£€ç´¢æ–‡çŒ®çš„åŸºå› ã€‚"
                else:
                    result = search_papers.run({"gene": gene, "limit": 3})
                    reply = gene_notice(gene, used_default, " è¿›è¡Œæ–‡çŒ®æ£€ç´¢") + result

            reply = append_suggestions(reply)
            session['messages'].append(AIMessage(content=reply))
            return jsonify({"response": reply, "session_id": session_id})

        # æ–‡çŒ®æŸ¥è¯¢è§¦å‘è¯
        literature_keywords = ["æ–‡çŒ®", "paper", "æœ€æ–°ç ”ç©¶", "ç ”ç©¶è¿›å±•", "related papers", "æŸ¥æ–‡çŒ®"]
        if any(keyword in user_message for keyword in literature_keywords):
            genes = extract_genes(user_message)
            notice = ""
            if genes:
                gene = genes[0]
                set_last_gene(session, gene)
            else:
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "æš‚æœªæ£€æµ‹åˆ°è¦æ£€ç´¢çš„åŸºå› ï¼Œè¯·å…ˆæä¾›åŸºå› åç§°ï¼ˆå¦‚ TP53ã€MEG3ï¼‰ã€‚"
                    session['messages'].append(AIMessage(content=reply))
                    return jsonify({"response": reply, "session_id": session_id})
                notice = gene_notice(gene, used_default, " è¿›è¡Œæ–‡çŒ®æ£€ç´¢")

            tool_result = search_papers.run({"gene": gene, "limit": 3})
            reply = append_suggestions(notice + tool_result)
            session['messages'].append(AIMessage(content=reply))
            return jsonify({"response": reply, "session_id": session_id})

        # Pathway æŸ¥è¯¢è§¦å‘è¯
        pathway_keywords = ["é€šè·¯", "pathway", "ä¿¡å·é€šè·¯", "ä»£è°¢é€šè·¯", "reactome"]
        if any(keyword in user_message for keyword in pathway_keywords):
            genes = extract_genes(user_message)
            notice = ""
            if genes:
                gene = genes[0]
                set_last_gene(session, gene)
            else:
                gene, used_default = resolve_gene(session)
                if not gene:
                    reply = "æ‚¨æƒ³æŸ¥è¯¢å“ªä¸ªåŸºå› çš„é€šè·¯ä¿¡æ¯ï¼Ÿä¾‹å¦‚ï¼šTP53ã€STAT1ã€MEG3ã€‚"
                    session['messages'].append(AIMessage(content=reply))
                    return jsonify({"response": reply, "session_id": session_id})
                notice = gene_notice(gene, used_default, " æŸ¥è¯¢ Reactome é€šè·¯")

            tool_result = query_pathways.run({
                "input_data": {
                    "query_gene": gene,
                    "limit": 10
                }
            })
            reply = append_suggestions(notice + tool_result)
            session['messages'].append(AIMessage(content=reply))
            return jsonify({"response": reply, "session_id": session_id})

        # CSV è‡ªåŠ¨åˆ†æè§¦å‘è¯
        csv_keywords = ["æœ€é«˜åˆ†", "top åŸºå› ", "æ˜¾è‘—åŸºå› ", "æœ€å¼ºåŸºå› "]
        if any(keyword in user_message for keyword in csv_keywords):
            csv_path = "data/gene_scores.csv"
            tool_result = analyze_csv.run({"file_path": csv_path, "top_n": 5})
            reply = append_suggestions(tool_result)
            session['messages'].append(AIMessage(content=reply))
            return jsonify({"response": reply, "session_id": session_id})

        # =============================
        # åŸºå› åç§°è‡ªåŠ¨è¯†åˆ« + å¤šå·¥å…·è”åŠ¨
        # =============================
        gene_candidates = extract_genes(user_message)

        if gene_candidates:
            gene = gene_candidates[0]
            set_last_gene(session, gene)

            # è”åŠ¨ï¼šOpenTargets + TRRUST
            opentargets_result = opentargets_query.run({"gene_symbol": gene})
            trrust_result = check_tf_coregulation.run({
                "tf_list_str": "",
                "target_gene": gene,
                "species": "auto"
            })

            combo_reply = (
                f"ğŸ” **æ£€æµ‹åˆ°åŸºå› ï¼š{gene}**\n\n"
                f"ğŸ“Œ **OpenTargets ç»“æœï¼š**\n{opentargets_result}\n\n"
                f"ğŸ“Œ **TRRUST è°ƒæ§å…³ç³»ï¼š**\n{trrust_result}\n\n"
                "å¦‚éœ€ç»§ç»­æŸ¥è¯¢å…¶ä»–åŸºå› ï¼Œè¯·å‘Šè¯‰æˆ‘åŸºå› åç§°ã€‚"
            )

            reply = append_suggestions(combo_reply)
            session['messages'].append(AIMessage(content=reply))
            return jsonify({"response": reply, "session_id": session_id})

        # è°ƒç”¨ agent
        result = agent.invoke(
            {"messages": session['messages']},
            config={"configurable": {"thread_id": session['thread_id']}}
        )

        # è·å– agent å›å¤
        reply_msg = result["messages"][-1]
        reply_content = append_suggestions(reply_msg.content)

        # ä¿å­˜åˆ°ä¼šè¯
        session['messages'].append(reply_msg)

        return jsonify({
            "response": reply_content,
            "session_id": session_id
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/new_session', methods=['POST'])
def new_session():
    """åˆ›å»ºæ–°ä¼šè¯"""
    session_id = str(uuid.uuid4())
    sessions[session_id] = {
        'messages': [system_prompt],
        'thread_id': f"thread_{session_id}",
        'last_gene': None
    }
    return jsonify({"session_id": session_id})


@app.route('/api/clear_session', methods=['POST'])
def clear_session():
    """æ¸…é™¤ä¼šè¯"""
    data = request.json
    session_id = data.get('session_id', 'default')

    if session_id in sessions:
        sessions[session_id] = {
            'messages': [system_prompt],
            'thread_id': f"thread_{session_id}",
            'last_gene': None
        }

    return jsonify({'status': 'cleared'})


if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5001)