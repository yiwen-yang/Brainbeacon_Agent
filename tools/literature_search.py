import requests
from langchain.tools import tool

@tool("search_papers", return_direct=True)
def search_papers(gene: str, limit: int = 5) -> str:
    """
    æŸ¥è¯¢æŸä¸ªåŸºå› çš„æœ€æ–°æ–‡çŒ®ï¼ˆä½¿ç”¨ Semantic Scholarï¼‰ã€‚
    åšäº†ä¼˜é›…å…œåº•ï¼š429ã€ç½‘ç»œé”™è¯¯ã€ç©ºç»“æœå‡ä¼šè¿”å›å‹å¥½çš„æç¤ºã€‚
    """

    url = (
        "https://api.semanticscholar.org/graph/v1/paper/search"
        f"?query={gene}&limit={limit}&fields=title,year,externalIds,url"
    )

    # --- ç½‘ç»œå¼‚å¸¸å…œåº• ---
    try:
        resp = requests.get(url, timeout=10)
    except Exception:
        return (
            "ğŸ“š æ–‡çŒ®æ£€ç´¢æš‚æ—¶æ— æ³•è¿æ¥åˆ° Semantic Scholarã€‚\n"
            "å¯èƒ½æ˜¯ç½‘ç»œä¸ç¨³å®šæˆ–æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
        )

    # --- çŠ¶æ€ç å…œåº•ï¼ˆç‰¹åˆ«å¤„ç† 429ï¼‰ ---
    if resp.status_code == 429:
        return (
            "ğŸ“š æ–‡çŒ®æœåŠ¡å½“å‰è¯·æ±‚è¿‡äºé¢‘ç¹ï¼ˆHTTP 429ï¼‰ã€‚\n\n"
            "å»ºè®®ï¼š\n"
            "- ç¨ç­‰å‡ åˆ†é’Ÿå†è¯•ï¼›\n"
            "- æˆ–ç»§ç»­æŸ¥çœ‹ OpenTargetsã€TRRUSTã€BrainBeacon çš„å…¶ä»–ä¿¡æ¯ã€‚\n"
        )

    if resp.status_code != 200:
        return f"ğŸ“š æ–‡çŒ®æŸ¥è¯¢å¤±è´¥ï¼ˆHTTP {resp.status_code}ï¼‰ã€‚è¯·ç¨åé‡è¯•ã€‚"

    # --- æ­£å¸¸è§£ææ•°æ® ---
    data = resp.json().get("data", [])
    if not data:
        return f"ğŸ“š æœªæ‰¾åˆ°ä¸ **{gene}** ç›¸å…³çš„æ–‡çŒ®ã€‚"

    results = []
    for p in data:
        title = p.get("title", "æ— æ ‡é¢˜")
        year = p.get("year", "æœªçŸ¥å¹´ä»½")
        external = p.get("externalIds", {})
        doi = external.get("DOI", None)

        url = p.get("url", "æ— é“¾æ¥")

        line = f"ğŸ“„ **{title}** ({year})\nğŸ”— é“¾æ¥ï¼š{url}"
        if doi:
            line += f"\nğŸ†” DOIï¼š{doi}"
        results.append(line + "\n")

    return "\n".join(results)